# Level 7 Diagnostic Analysis: Moral Judgment Study

---

## I. THE INITIAL FALSIFIABLE CLAIM

**The study's deepest structural problem is mechanism opacity: its design is constitutionally incapable of distinguishing the predicted causal pathway (cognitive resource depletion → reduced System 2 deliberation → increased utilitarian responding) from at least three alternative pathways that produce identical behavioral signatures, making any significant finding uninterpretable regardless of statistical validity.**

*Falsifiability condition:* If the design contains measures that independently identify which pathway generated observed responses, the claim fails.

---

## II. THE DIALECTIC

### Expert A — Defender (Cognitive Neuroscientist)
"Mechanism opacity is manageable. Response time in the secondary analysis *is* a process measure—longer responses under low load indicate deliberation, shorter responses under high load indicate System 1 engagement. Confidence ratings add another discriminant. The claim sets an impossible standard: no experiment can rule out every alternative. The manipulation is well-validated in working memory literature."

*Pressure applied:* The defender forces the claim to specify which alternatives are actually ruled out by the existing secondary measures.

### Expert B — Attacker (Moral Philosopher/Replication Researcher)
"The claim doesn't go far enough. Mechanism opacity is a symptom. The deeper failure is that the theoretical substrate—Greene's dual-process model—has a contested replication record with personal/impersonal dilemma distinctions showing high variability across stimuli sets and populations. The study is testing a mechanism for a framework whose empirical base is already destabilized. You can't identify which pathway is active if the pathway map itself is unreliable."

*Pressure applied:* The attacker relocates the problem from execution to foundation, making mechanism opacity derivative of theory failure.

### Expert C — Prober (Methodologist)
"Both of you assume the outcome measure—a 7-point acceptability Likert—is actually capturing 'utilitarian versus deontological responding.' Neither of you has questioned this. The scale measures *expressed acceptability*, which conflates moral framework endorsement, emotional reaction, social norm sensitivity, and demand characteristics. The defender thinks process measures can identify the pathway; the attacker thinks the pathway map is wrong. Both presuppose the scale is measuring movement along *some* moral-reasoning dimension. It might be measuring something orthogonal to moral reasoning entirely."

*Pressure applied:* The prober reveals that both the defender and attacker are arguing about the input side (manipulations, theory) while the output side (measurement) is doing unexamined foundational work.

---

## III. THE TRANSFORMED CLAIM

After dialectical pressure, the claim shifts from:

> *The design cannot distinguish between causal pathways* (manipulation-side problem)

to:

> *The outcome measure is simultaneously proxying for reasoning process type, moral framework endorsement, and behavioral disposition—three interpretively inconsistent constructs—while the theoretical framework retroactively legitimizes whichever reading fits the result* (measurement-side problem, theoretically camouflaged)

---

## IV. THE GAP AS DIAGNOSTIC

| | Original Claim | Transformed Claim |
|---|---|---|
| **Locus** | Independent variable (manipulation) | Dependent variable (measure) |
| **Type** | Process indeterminacy | Construct indeterminacy |
| **Direction** | Input → mechanism | Mechanism → output |
| **Visibility** | Partially visible (experts discuss manipulation quality) | Nearly invisible (assumed away by theoretical framing) |

**What the gap reveals:** The dialectic began by examining what the manipulations do to participants and ended by questioning what the scale captures from them. This directional reversal is not random. It reveals that the design's sophistication is *concentrated on the input side*—four conditions, validated manipulations, randomized dilemma order, exclusion criteria—while the output side (a single 7-point scale, averaged across 6 heterogeneous dilemmas) receives virtually no structural scrutiny. The complexity of the apparatus creates an attentional asymmetry: reviewers interrogate what was *done* to participants and miss examining what is *extracted* from them.

---

## V. THE CONCEALMENT MECHANISM: **Theoretical Laundering**

The 7-point acceptability scale has no independent validity as a measure of "utilitarian versus deontological reasoning." It measures acceptability. The theoretical framework—Greene's dual-process model—performs a laundering operation: by invoking the theory *before* presenting the measure, the study borrows the theory's interpretive vocabulary and applies it to the scale's outputs as if the theory had validated the instrument. It hasn't. The scale is legitimized through theoretical association rather than psychometric demonstration.

**Structural signature:** Theory precedes measurement validation; citations substitute for construct validity evidence; the measure is presented as *obviously* tracking the theoretical construct because the theoretical framing has already been accepted.

This mechanism is specific: it differs from ordinary theoretical assumption because it *actively conceals* the gap between "what the scale captures" and "what the theory requires the scale to capture."

---

## VI. APPLYING THE MECHANISM: WHAT IS STILL HIDDEN

Now apply theoretical laundering as a detection lens to find what the *entire dialectic*—including the prober's intervention—failed to surface:

### Hidden Problem 1: The Aggregation Fraud
The study collapses 6 personal dilemmas into one "personal score" and 6 impersonal into one "impersonal score." This is treated as unproblematic because the theoretical framework defines "personal" and "impersonal" as coherent categories. But individual dilemmas within each category vary dramatically on emotional valence, causal proximity, protagonist salience, and base rates of utilitarian responding (literature shows coefficient of variation across trolley-type dilemmas can exceed 40%). Averaging annihilates this variance. The theory launders the aggregation: because "personal dilemmas" is theoretically coherent, averaging across them appears methodologically coherent. The ANOVA runs on phantom constructs. **No expert in the dialectic questioned whether the repeated-measures factor ("dilemma type") corresponds to a real psychological dimension or is a theoretically-imposed categorization.**

### Hidden Problem 2: Pseudo-Falsifiability
The dialectic accepted the study's self-description as falsifiable. It isn't—not because of a logical flaw, but because theoretical laundering provides post-hoc interpretive rescue for any result:

- *Significant interaction as predicted* → confirms dual-process theory
- *Null interaction* → "manipulation failed to achieve adequate load" or "ceiling effects in utilitarian responding"
- *Reversed interaction* → "time pressure paradoxically enabled deliberation" (known finding that can be assimilated)
- *Effect on impersonal but not personal dilemmas* → "personal dilemmas resist load due to stronger affective anchoring"

The study *appears* falsifiable because it states a directional prediction. But the theoretical framework that launders the measure also supplies an unfalsifiability net. **The exclusion criteria—excluding philosophy and psychology majors—actually tightens this pseudo-falsifiability: by selecting participants least able to articulate their reasoning process, the study maximizes interpretive freedom for the researcher while presenting methodological rigor as justification.**

### Hidden Problem 3: The Response-Compression Artifact (Still Hiding)
Neither the original claim, the dialectic, nor the transformed claim addressed this: **time pressure doesn't only affect which cognitive system dominates—it mechanically compresses response distributions.** Under 15-second time pressure, participants avoid extreme scale positions not because they are reasoning differently but because committing to an extreme requires confidence they haven't had time to develop. This would produce *apparent* moderation (regression toward scale center) that the theoretical framework would misread as "increased utilitarian responding" (utilitarian responses tend toward the mid-to-high acceptability range for most trolley-type dilemmas). The Likert scale, unvalidated as a process measure, cannot distinguish "genuinely utilitarian judgment" from "response compression artifact." Theoretical laundering has made this invisible because the theory doesn't predict response compression—it predicts framework shift—so the instrument is never interrogated for compression sensitivity.

---

## VII. SYNTHESIS: THE REAL STRUCTURAL PROBLEM

The study has not one deep problem but a recursive architecture of concealment:

```
Well-specified manipulations
    → create appearance of experimental rigor
        → legitimize borrowing of theoretical framework
            → theoretical framework launders outcome measure
                → laundered measure aggregates across heterogeneous stimuli
                    → aggregation produces a pseudo-construct
                        → pseudo-construct is tested with adequate power
                            → for the wrong hypothesis
                                → with an unfalsifiable safety net
```

The deepest problem is not underpowering, not construct validity of the manipulation, not theory failure—it is that the study's visible sophistication (four conditions, mixed design, Bonferroni correction, power analysis, exclusion criteria) functions as a concealment system for the near-total absence of measurement validity at the point where evidence is actually extracted. Every element the study got right directs attention away from the one thing it got most wrong.
